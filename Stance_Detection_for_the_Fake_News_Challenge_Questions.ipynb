{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QI9jhXKPCFcJ"
   },
   "source": [
    "# Stance Detection for the Fake News Challenge\n",
    "\n",
    "## Identifying Textual Relationships with Deep Neural Nets\n",
    "\n",
    "### Check the problem context [here](https://drive.google.com/open?id=1KfWaZyQdGBw8AUTacJ2yY86Yxgw2Xwq0).\n",
    "\n",
    "### Download files required for the project from [here](https://drive.google.com/open?id=10yf39ifEwVihw4xeJJR60oeFBY30Y5J8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vSNgdEMpenpE"
   },
   "source": [
    "## Step1: Load the given dataset  \n",
    "\n",
    "1. Mount the google drive\n",
    "\n",
    "2. Import Glove embeddings\n",
    "\n",
    "3. Import the test and train datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aPOZRohMiSpQ"
   },
   "source": [
    "### Mount the google drive to access required project files\n",
    "\n",
    "Run the below commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7AS39z1XgFpT"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_7yCFdzgFsH"
   },
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhZdJ4zpwWzN"
   },
   "source": [
    "#### Path for Project files on google drive\n",
    "\n",
    "**Note:** You need to change this path according where you have kept the files in google drive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aol97RUogFuS"
   },
   "outputs": [],
   "source": [
    "# project_path = \"/content/drive/My Drive/Datasets/Fake News Challenge/\"\n",
    "project_path = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ly0VxAnwJ2f"
   },
   "source": [
    "### Loading the Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xmsPn6PF-cgL"
   },
   "outputs": [],
   "source": [
    "# from zipfile import ZipFile\n",
    "# with ZipFile(project_path+'glove.6B.zip', 'r') as z:\n",
    "#     z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TjLJEQ_PwcGi"
   },
   "source": [
    "# Load the dataset [5 Marks]\n",
    "\n",
    "1. Using [read_csv()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) in pandas load the given train datasets files **`train_bodies.csv`** and **`train_stances.csv`**\n",
    "\n",
    "2. Using [merge](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) command in pandas merge the two datasets based on the Body ID. \n",
    "\n",
    "Note: Save the final merged dataset in a dataframe with name **`dataset`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7gXO1WZ-gFwm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_bodies:  (1683, 2)\n",
      "train_stances:  (49972, 3)\n",
      "\n",
      "Unique Body ID in train_bodies:  1683\n",
      "Unique Body ID in train_stances:  1683\n",
      "...\n",
      "Common entries:  1683\n"
     ]
    }
   ],
   "source": [
    "train_bodies = pd.read_csv('data/train_bodies.csv')\n",
    "train_stances = pd.read_csv('data/train_stances.csv')\n",
    "\n",
    "print('train_bodies: ', train_bodies.shape)\n",
    "print('train_stances: ', train_stances.shape)\n",
    "#\n",
    "print()\n",
    "#\n",
    "# print('train_bodies: \\n', train_bodies.head())\n",
    "# print('train_stances: \\n', train_stances.head())\n",
    "\n",
    "#### Check how many common bodies exist between train_bodies and train_stances\n",
    "def common_member(a, b): \n",
    "    a_set = set(a) \n",
    "    b_set = set(b) \n",
    "    if (a_set & b_set): \n",
    "        return (a_set & b_set) \n",
    "    else: \n",
    "        print(\"No common elements\")\n",
    "\n",
    "#\n",
    "print('Unique Body ID in train_bodies: ', len(sorted(train_bodies['Body ID'].unique())))\n",
    "print('Unique Body ID in train_stances: ', len(sorted(train_stances['Body ID'].unique())))\n",
    "#\n",
    "print('...')\n",
    "print('Common entries: ', len(common_member(train_bodies['Body ID'], train_stances['Body ID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kosAWskdOOT8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 4)\n"
     ]
    }
   ],
   "source": [
    "#### Merge by 'Body ID'\n",
    "dataset = pd.merge(train_stances, train_bodies, on='Body ID')\n",
    "\n",
    "#### Reorder columns\n",
    "dataset = dataset.reindex(columns=['Body ID', 'articleBody', 'Headline', 'Stance']).sort_values(['Body ID'])\n",
    "\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g4ycQbBCg20S"
   },
   "source": [
    "\n",
    "<h2> Check1:</h2>\n",
    "  \n",
    "<h3> You should see the below output if you run `dataset.head()` command as given below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "IUtF7iOmj11k",
    "outputId": "f78f6146-e7b4-49c7-e8f2-c33b4611c08d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>41651</td>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>Soldier shot, Parliament locked down after gun...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41657</td>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>Italian catches huge wels catfish; is it a rec...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41658</td>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>Not coming to a store near you: The pumpkin sp...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41659</td>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>One gunman killed in shooting on Parliament Hi...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41660</td>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>Soldier shot at war memorial in Canada</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Body ID                                        articleBody  \\\n",
       "41651        0  A small meteorite crashed into a wooded area i...   \n",
       "41657        0  A small meteorite crashed into a wooded area i...   \n",
       "41658        0  A small meteorite crashed into a wooded area i...   \n",
       "41659        0  A small meteorite crashed into a wooded area i...   \n",
       "41660        0  A small meteorite crashed into a wooded area i...   \n",
       "\n",
       "                                                Headline     Stance  \n",
       "41651  Soldier shot, Parliament locked down after gun...  unrelated  \n",
       "41657  Italian catches huge wels catfish; is it a rec...  unrelated  \n",
       "41658  Not coming to a store near you: The pumpkin sp...  unrelated  \n",
       "41659  One gunman killed in shooting on Parliament Hi...  unrelated  \n",
       "41660             Soldier shot at war memorial in Canada  unrelated  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tjzVz2ifijmj"
   },
   "source": [
    "## Step2: Data Pre-processing and setting some hyper parameters needed for model\n",
    "\n",
    "\n",
    "#### Run the code given below to set the required parameters.\n",
    "\n",
    "1. `MAX_SENTS` = Maximum no.of sentences to consider in an article.\n",
    "\n",
    "2. `MAX_SENT_LENGTH` = Maximum no.of words to consider in a sentence.\n",
    "\n",
    "3. `MAX_NB_WORDS` = Maximum no.of words in the total vocabualry.\n",
    "\n",
    "4. `MAX_SENTS_HEADING` = Maximum no.of sentences to consider in a heading of an article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDXSdpvqjuqw"
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 20000\n",
    "MAX_SENTS = 20\n",
    "MAX_SENTS_HEADING = 1\n",
    "MAX_SENT_LENGTH = 20\n",
    "VALIDATION_SPLIT = 0.2\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zwE7CPHdiDT-"
   },
   "source": [
    "### Download the `Punkt` from nltk using the commands given below. This is for sentence tokenization.\n",
    "\n",
    "For more info on how to use it, read [this](https://stackoverflow.com/questions/35275001/use-of-punktsentencetokenizer-in-nltk).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "lsiKmyJUZ-hU",
    "outputId": "9b4f85c8-189c-4af9-cdab-4b244a8a5a72"
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gqwm_GbwwnhX"
   },
   "source": [
    "# Tokenizing the text and loading the pre-trained Glove word embeddings for each token  [5 marks] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WfZLR24mm32k"
   },
   "source": [
    "Keras provides [Tokenizer API](https://keras.io/preprocessing/text/) for preparing text. Read it before going any further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fLSn9S-5oG4Z"
   },
   "source": [
    "#### Import the Tokenizer from keras preprocessing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S-VUgh2yoMlR",
    "outputId": "406d3d0c-c2ae-4456-dbbd-23abaf6db2cc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eml0Lge4oOuh"
   },
   "source": [
    "#### Initialize the Tokenizer class with maximum vocabulary count as `MAX_NB_WORDS` initialized at the start of step2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qm85qirPofc2"
   },
   "outputs": [],
   "source": [
    "# Replace out-of-vocabulary words with token\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, split=' ', oov_token='oov_token', lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HBe1KuXDosJ7"
   },
   "source": [
    "#### Now, using fit_on_texts() from Tokenizer class, lets encode the data \n",
    "\n",
    "Note: We need to fit articleBody and Headline also to cover all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q5rk-UyBlmyA"
   },
   "outputs": [],
   "source": [
    "tokenizer_dataset = dataset['articleBody'] + dataset['Headline']\n",
    "\n",
    "tokenizer.fit_on_texts(tokenizer_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a :  478453\n",
      "house :  5738\n",
      "oov_token :  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49972"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(tokenizer.word_counts.keys())[0], ': ', tokenizer.word_counts[list(tokenizer.word_counts.keys())[0]])\n",
    "print(list(tokenizer.word_docs.keys())[0], ': ', tokenizer.word_docs[list(tokenizer.word_docs.keys())[0]])\n",
    "print(list(tokenizer.word_index.keys())[0], ': ', tokenizer.word_index[list(tokenizer.word_index.keys())[0]])\n",
    "tokenizer.document_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "omptHX-JpBsN"
   },
   "source": [
    "#### fit_on_texts() gives the following attributes in the output as given [here](https://faroit.github.io/keras-docs/1.2.2/preprocessing/text/).\n",
    "\n",
    "* **word_counts:** dictionary mapping words (str) to the number of times they appeared on during fit. Only set after fit_on_texts was called.\n",
    "\n",
    "* **word_docs:** dictionary mapping words (str) to the number of documents/texts they appeared on during fit. Only set after fit_on_texts was called.\n",
    "\n",
    "* **word_index:** dictionary mapping words (str) to their rank/index (int). Only set after fit_on_texts was called.\n",
    "\n",
    "* **document_count:** int. Number of documents (texts/sequences) the tokenizer was trained on. Only set after fit_on_texts or fit_on_sequences was called.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SHnsT2sTtFAA"
   },
   "source": [
    "### Now, tokenize the sentences using nltk sent_tokenize() and encode the senteces with the ids we got form the above `t.word_index`\n",
    "\n",
    "Initialise 2 lists with names `texts` and `articles`.\n",
    "\n",
    "```\n",
    "texts = [] to store text of article as it is.\n",
    "\n",
    "articles = [] split the above text into a list of sentences.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ctEu-d4c4EZs"
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "articles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 49972/49972 [01:10<00:00, 705.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# from nltk.tokenize import sent_tokenize\n",
    "\n",
    "for text in tqdm(dataset['articleBody']):\n",
    "    texts.append(text)\n",
    "    articles.append(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(texts))\n",
    "# print(len(articles))\n",
    "# print(texts[0])\n",
    "# print('---')\n",
    "# print(articles[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koTVJjoO6P78"
   },
   "source": [
    "## Check 2:\n",
    "\n",
    "first element of texts and articles should be as given below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "3mWBW99p5UW9",
    "outputId": "b335efb0-44e3-4ad8-b82b-628625451cce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A small meteorite crashed into a wooded area in Nicaragua\\'s capital of Managua overnight, the government said Sunday. Residents reported hearing a mysterious boom that left a 16-foot deep crater near the city\\'s airport, the Associated Press reports. \\n\\nGovernment spokeswoman Rosario Murillo said a committee formed by the government to study the event determined it was a \"relatively small\" meteorite that \"appears to have come off an asteroid that was passing close to Earth.\" House-sized asteroid 2014 RC, which measured 60 feet in diameter, skimmed the Earth this weekend, ABC News reports. \\nMurillo said Nicaragua will ask international experts to help local scientists in understanding what happened.\\n\\nThe crater left by the meteorite had a radius of 39 feet and a depth of 16 feet,  said Humberto Saballos, a volcanologist with the Nicaraguan Institute of Territorial Studies who was on the committee. He said it is still not clear if the meteorite disintegrated or was buried.\\n\\nHumberto Garcia, of the Astronomy Center at the National Autonomous University of Nicaragua, said the meteorite could be related to an asteroid that was forecast to pass by the planet Saturday night.\\n\\n\"We have to study it more because it could be ice or rock,\" he said.\\n\\nWilfried Strauch, an adviser to the Institute of Territorial Studies, said it was \"very strange that no one reported a streak of light. We have to ask if anyone has a photo or something.\"\\n\\nLocal residents reported hearing a loud boom Saturday night, but said they didn\\'t see anything strange in the sky.\\n\\n\"I was sitting on my porch and I saw nothing, then all of a sudden I heard a large blast. We thought it was a bomb because we felt an expansive wave,\" Jorge Santamaria told The Associated Press.\\n\\nThe site of the crater is near Managua\\'s international airport and an air force base. Only journalists from state media were allowed to visit it.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "WtIjO3ht5EKA",
    "outputId": "9d3db104-1085-49e9-c245-7e9e92b4f60c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"A small meteorite crashed into a wooded area in Nicaragua's capital of Managua overnight, the government said Sunday.\",\n",
       " \"Residents reported hearing a mysterious boom that left a 16-foot deep crater near the city's airport, the Associated Press reports.\",\n",
       " 'Government spokeswoman Rosario Murillo said a committee formed by the government to study the event determined it was a \"relatively small\" meteorite that \"appears to have come off an asteroid that was passing close to Earth.\"',\n",
       " 'House-sized asteroid 2014 RC, which measured 60 feet in diameter, skimmed the Earth this weekend, ABC News reports.',\n",
       " 'Murillo said Nicaragua will ask international experts to help local scientists in understanding what happened.',\n",
       " 'The crater left by the meteorite had a radius of 39 feet and a depth of 16 feet,  said Humberto Saballos, a volcanologist with the Nicaraguan Institute of Territorial Studies who was on the committee.',\n",
       " 'He said it is still not clear if the meteorite disintegrated or was buried.',\n",
       " 'Humberto Garcia, of the Astronomy Center at the National Autonomous University of Nicaragua, said the meteorite could be related to an asteroid that was forecast to pass by the planet Saturday night.',\n",
       " '\"We have to study it more because it could be ice or rock,\" he said.',\n",
       " 'Wilfried Strauch, an adviser to the Institute of Territorial Studies, said it was \"very strange that no one reported a streak of light.',\n",
       " 'We have to ask if anyone has a photo or something.\"',\n",
       " \"Local residents reported hearing a loud boom Saturday night, but said they didn't see anything strange in the sky.\",\n",
       " '\"I was sitting on my porch and I saw nothing, then all of a sudden I heard a large blast.',\n",
       " 'We thought it was a bomb because we felt an expansive wave,\" Jorge Santamaria told The Associated Press.',\n",
       " \"The site of the crater is near Managua's international airport and an air force base.\",\n",
       " 'Only journalists from state media were allowed to visit it.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fpuRIA7cCfcY"
   },
   "source": [
    "# Now iterate through each article and each sentence to encode the words into ids using t.word_index  [5 marks] \n",
    "\n",
    "Here, to get words from sentence you can use `text_to_word_sequence` from keras preprocessing text.\n",
    "\n",
    "1. Import text_to_word_sequence\n",
    "\n",
    "2. Initialize a variable of shape (no.of articles, MAX_SENTS, MAX_SENT_LENGTH) with name `data` with zeros first (you can use numpy [np.zeros](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html) to initialize with all zeros)and then update it while iterating through the words and sentences in each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YVyClBULCqWj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 49972/49972 [00:36<00:00, 1364.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "data = np.zeros(shape=(len(articles), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "\n",
    "for i in tqdm(range(len(articles))):\n",
    "    #print(i)\n",
    "    article = articles[i]\n",
    "    for j, sent in enumerate(article):\n",
    "        if j < MAX_SENTS:\n",
    "            words = text_to_word_sequence(sent)\n",
    "            k=0\n",
    "            for w in words:\n",
    "                if k < MAX_SENT_LENGTH:\n",
    "                    if w in tokenizer.word_index:\n",
    "                        data[i, j, k] = tokenizer.word_index[w]\n",
    "                    k += 1\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bFdmiDYcE144"
   },
   "source": [
    "### Check 3:\n",
    "\n",
    "Accessing first element in data should give something like given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1037
    },
    "colab_type": "code",
    "id": "TsFWW5C2Djog",
    "outputId": "ec1daf8f-1e56-4e3d-b6e3-b40a06c406b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    4,   486,   434,  7205,    82,     4,  3733,   332,     6,\n",
       "         3889,   351,     5,  1433,  2957,     2,    90,    13,   465,\n",
       "            0,     0],\n",
       "       [  758,    96,  1046,     4,  2676,  1751,     8,   189,     4,\n",
       "         1218,  1075,  2027,   699,   159,     2,  3030,   450,     2,\n",
       "          556,   244],\n",
       "       [   90,  1066,  4112,  2346,    13,     4,  1093,  3301,    20,\n",
       "            2,    90,     3,  1792,     2,   530,  2006,    16,    10,\n",
       "            4,  3108],\n",
       "       [  187,  3640,   972,   203,  2554,    44,  6771,  1720,  1251,\n",
       "            6, 13307, 17922,     2,   777,    32,   739,  3987,    68,\n",
       "           86,     0],\n",
       "       [ 2346,    13,  1585,    39,  1095,   352,   778,     3,   368,\n",
       "          261,  1776,     6,  4448,    71,   495,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [    2,   699,   189,    20,     2,   434,    33,     4,  7412,\n",
       "            5,  2257,  1251,     7,     4,  5267,     5,  1218,  1251,\n",
       "           13,  3360],\n",
       "       [   14,    13,    16,     9,   149,    26,   542,    65,     2,\n",
       "          434,  3727,    42,    10,  1849,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [ 3360,  5730,     5,     2,  5870,   614,    22,     2,   309,\n",
       "         3433,   797,     5,  1585,    13,     2,   434,    70,    24,\n",
       "          786,     3],\n",
       "       [   38,    18,     3,  1792,    16,    53,   121,    16,    70,\n",
       "           24,  4917,    42,  1961,    14,    13,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [ 4734,  3335,    25,  3966,     3,     2,  1315,     5,  3068,\n",
       "         1652,    13,    16,    10,   196,  1424,     8,    59,    41,\n",
       "           96,     4],\n",
       "       [   38,    18,     3,  1095,    65,   510,    21,     4,   251,\n",
       "           42,   265,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [  261,   758,    96,  1046,     4,  1805,  1751,   531,   276,\n",
       "           29,    13,    34,   701,   164,   892,  1424,     6,     2,\n",
       "         2079,     0],\n",
       "       [   36,    10,  2058,    11,   117,  5821,     7,    36,   575,\n",
       "          656,   105,    60,     5,     4,  2408,    36,   241,     4,\n",
       "          512,  1911],\n",
       "       [   38,   341,    16,    10,     4,  2080,   121,    38,   881,\n",
       "           25,  4449,  2582,  4316,  4918,    56,     2,   556,   244,\n",
       "            0,     0],\n",
       "       [    2,   256,     5,     2,   699,     9,   159,  3958,   352,\n",
       "          450,     7,    25,   155,   466,  1927,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [  127,   922,    23,    48,   101,    37,  1833,     3,  1213,\n",
       "           16,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTG6JySHehkT"
   },
   "source": [
    "# Repeat the same process for the `Headings` as well. Use variables with names `texts_heading` and `articles_heading` accordingly. [5 marks] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_CliiIhLemJV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 49972/49972 [00:03<00:00, 14342.73it/s]\n"
     ]
    }
   ],
   "source": [
    "texts_heading = []\n",
    "articles_heading = []\n",
    "\n",
    "for text in tqdm(dataset['Headline']):\n",
    "    texts_heading.append(text)\n",
    "    articles_heading.append(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soldier shot, Parliament locked down after gunfire erupts at war memorial\n",
      "---\n",
      "['Soldier shot, Parliament locked down after gunfire erupts at war memorial']\n"
     ]
    }
   ],
   "source": [
    "# print(len(texts_heading))\n",
    "# print(len(articles_heading))\n",
    "print(texts_heading[0])\n",
    "print('---')\n",
    "print(articles_heading[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 49972/49972 [00:02<00:00, 24057.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Soldier shot, Parliament locked down after gunfire erupts at war memorial']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  734,   210,   344,  7113,   193,    35,  1335, 11488,    22,\n",
       "          234,   684,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "data_heading = np.zeros(shape=(len(articles_heading), 1, MAX_SENT_LENGTH), dtype='int32')\n",
    "\n",
    "for i in tqdm(range(len(articles_heading))):\n",
    "    #print(i)\n",
    "    article = articles_heading[i]\n",
    "    for j, sent in enumerate(article):\n",
    "        if j < 1:\n",
    "            words = text_to_word_sequence(sent)\n",
    "            k=0\n",
    "            for w in words:\n",
    "                if k < MAX_SENT_LENGTH:\n",
    "                    if w in tokenizer.word_index:\n",
    "                        data_heading[i, j, k] = tokenizer.word_index[w]\n",
    "                    k += 1\n",
    "\n",
    "#\n",
    "print(articles_heading[0])\n",
    "data_heading[0, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iaH0Ey1qe_Co"
   },
   "source": [
    "### Now the features are ready, lets make the labels ready for the model to process.\n",
    "\n",
    "### Convert labels into one-hot vectors\n",
    "\n",
    "You can use [get_dummies](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) in pandas to create one-hot vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zq-VcgM8fat1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agree</th>\n",
       "      <th>disagree</th>\n",
       "      <th>discuss</th>\n",
       "      <th>unrelated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>41651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41657</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41658</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41659</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       agree  disagree  discuss  unrelated\n",
       "41651      0         0        0          1\n",
       "41657      0         0        0          1\n",
       "41658      0         0        0          1\n",
       "41659      0         0        0          1\n",
       "41660      0         0        0          1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.get_dummies(dataset.Stance)\n",
    "print(labels.shape)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 4:\n",
    "\n",
    "The shape of data and labels shoould match the given below numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "vpEWEnjFfnFR",
    "outputId": "312006c9-6dff-4704-978e-d08131b483c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (49972, 20, 20)\n",
      "Shape of label tensor: (49972, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sDOxHdR3frDu"
   },
   "source": [
    "### Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ra-yYTvfzRt"
   },
   "outputs": [],
   "source": [
    "## get numbers upto no.of articles\n",
    "indices = np.arange(data.shape[0])\n",
    "## shuffle the numbers\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKnSqwIFf3Iy"
   },
   "outputs": [],
   "source": [
    "## shuffle the data\n",
    "data = data[indices]\n",
    "data_heading = data_heading[indices]\n",
    "## shuffle the labels according to data\n",
    "labels = labels.iloc[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JcOFVfPBf9kA"
   },
   "source": [
    "### Split into train and validation sets. Split the train set 80:20 ratio to get the train and validation sets.\n",
    "\n",
    "\n",
    "Use the variable names as given below:\n",
    "\n",
    "x_train, x_val - for body of articles.\n",
    "\n",
    "x-heading_train, x_heading_val - for heading of articles.\n",
    "\n",
    "y_train - for training labels.\n",
    "\n",
    "y_val - for validation labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5u3PTz3gEV-"
   },
   "outputs": [],
   "source": [
    "x_train, x_val, x_heading_train, x_heading_val, y_train, y_val = train_test_split(data, data_heading, labels, \n",
    "                                                                                  test_size = 0.20, \n",
    "                                                                                  random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UTyvoHrsgMDw"
   },
   "source": [
    "### Check 5:\n",
    "\n",
    "The shape of x_train, x_val, y_train and y_val should match the below numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "KLEbiw2Yghe2",
    "outputId": "e2390c42-fcda-4165-ae0e-52bd515d8b1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39977, 20, 20)\n",
      "(39977, 4)\n",
      "(9995, 20, 20)\n",
      "(9995, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yNnoBtArhJ1E"
   },
   "source": [
    "### Create embedding matrix with the glove embeddings\n",
    "\n",
    "\n",
    "Run the below code to create embedding_matrix which has all the words and their glove embedding if present in glove word list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eKqn2IL2ZF8v",
    "outputId": "076e80d8-5a98-434e-eb51-a5f02f532c7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "# f = open('./glove.6B.100d.txt')\n",
    "f = open('data//glove pretrained embeddings//glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# create a weight matrix for words in training docs\n",
    "# embedding_matrix = np.zeros((vocab_size, 100))\n",
    "# embedding_matrix = np.zeros((MAX_NB_WORDS, 100))\n",
    "embedding_matrix = np.zeros((len(tokenizer.word_index), EMBEDDING_DIM))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33643, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33643"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embedding_matrix.shape)\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LRi4o3ZspDFU"
   },
   "source": [
    "# Try the sequential model approach and report the accuracy score. [10 marks]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zSZDnPWkw2ZZ"
   },
   "source": [
    "### Import layers from Keras to build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFERENCE:\n",
    "- https://keras.io/examples/imdb_cnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5AgwQsfMrzAQ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, BatchNormalization\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling1D, Flatten\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gpkVhIbx3gr1"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "REFERENCE: https://stackoverflow.com/questions/46155868/keras-embedding-\n",
    "\n",
    "It order to use words for natural language processing or machine learning tasks, \n",
    "it is necessary to first map them onto a continuous vector space, thus creating \n",
    "word vectors or word embeddings. The Keras Embedding layer is useful for constructing \n",
    "such word vectors.\n",
    "\n",
    "input_dim : the vocabulary size. This is how many unique words are represented in your corpus.\n",
    "\n",
    "output_dim : the desired dimension of the word vector. For example, if output_dim = 100, \n",
    "then every word will be mapped onto a vector with 100 elements, whereas if output_dim = 300, \n",
    "then every word will be mapped onto a vector with 300 elements.\n",
    "\n",
    "input_length : the length of your sequences. For example, if your data consists of sentences, \n",
    "then this variable represents how many words there are in a sentence. As disparate sentences \n",
    "typically contain different number of words, it is usually required to pad your sequences \n",
    "such that all sentences are of equal length. The keras.preprocessing.pad_sequence method \n",
    "can be used for this (https://keras.io/preprocessing/sequence/).\n",
    "\"\"\"\n",
    "\n",
    "#### Create pre-trained embedding object\n",
    "# embedding_layer = Embedding(len(tokenizer.word_index),\n",
    "#                             EMBEDDING_DIM,\n",
    "#                             weights=[embedding_matrix],\n",
    "#                             input_length=MAX_SENT_LENGTH,\n",
    "#                             trainable=False)\n",
    "\n",
    "embedding_layer = Embedding(len(tokenizer.word_index),\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=[20,20],\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_8QXh-rmPFq"
   },
   "outputs": [],
   "source": [
    "# # embed_dim = 128 # 30 # 128\n",
    "# lstm_out = 196 # 128 # 196\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(embedding_layer)\n",
    "# model.add(Bidirectional(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(4, activation='softmax'))\n",
    "# model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Reference CNN: https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "# Reference model: https://keras.io/getting-started/functional-api-guide/\n",
    "#\n",
    "# sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "sequence_input = Input(shape=(400,), dtype='int32', name='articleInput')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x1 = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "# x1 = Conv2D(128, kernel_size=(3, 3), activation='relu', name='conv_1')(embedded_sequences)\n",
    "x1 = MaxPooling1D(5)(x1)\n",
    "x1 = Conv1D(128, 5, activation='relu')(x1)\n",
    "x1 = MaxPooling1D(5)(x1)\n",
    "x1 = Conv1D(128, 5, activation='relu')(x1)\n",
    "x1 = MaxPooling1D(5)(x1)  # global max pooling\n",
    "x1 = Flatten()(x1)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "#\n",
    "sequence_input2 = Input(shape=(20,), dtype='int32', name='headingInput')\n",
    "embedded_sequences2 = embedding_layer(sequence_input2)\n",
    "x2 = Conv1D(128, 5, activation='relu')(embedded_sequences2)\n",
    "x2 = MaxPooling1D(5)(x2)\n",
    "# x2 = Conv1D(128, 5, activation='relu')(x2)\n",
    "# x2 = MaxPooling1D(5)(x2)\n",
    "# x2 = Conv1D(128, 5, activation='relu')(x2)\n",
    "# x2 = MaxPooling1D(5)(x2)  # global max pooling\n",
    "x2 = Flatten()(x2)\n",
    "x2 = Dense(128, activation='relu')(x2)\n",
    "\n",
    "#\n",
    "x = concatenate([x1, x2])\n",
    "#\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 128)\n",
      "(None, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x1.shape)\n",
    "print(x2.shape)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "articleInput (InputLayer)       [(None, 400)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         multiple             3364300     articleInput[0][0]               \n",
      "                                                                 headingInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_202 (Conv1D)             (None, 396, 128)     64128       embedding_2[92][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_172 (MaxPooling1D (None, 79, 128)      0           conv1d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_203 (Conv1D)             (None, 75, 128)      82048       max_pooling1d_172[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "headingInput (InputLayer)       [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_173 (MaxPooling1D (None, 15, 128)      0           conv1d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_204 (Conv1D)             (None, 11, 128)      82048       max_pooling1d_173[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_205 (Conv1D)             (None, 16, 128)      64128       embedding_2[93][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_174 (MaxPooling1D (None, 2, 128)       0           conv1d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_175 (MaxPooling1D (None, 3, 128)       0           conv1d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 256)          0           max_pooling1d_174[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 384)          0           max_pooling1d_175[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 128)          32896       flatten_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 128)          49280       flatten_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256)          0           dense_35[0][0]                   \n",
      "                                                                 dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 64)           16448       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 64)           4160        dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 64)           4160        dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stanceOutput (Dense)            (None, 4)            260         dense_39[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,763,856\n",
      "Trainable params: 399,556\n",
      "Non-trainable params: 3,364,300\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# preds = Dense(len(labels_index), activation='softmax')(x)\n",
    "main_output = Dense(4, activation='softmax', name='stanceOutput')(x)\n",
    "\n",
    "model = Model(inputs = [sequence_input, sequence_input2], outputs=main_output)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "#\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5Xrd-JQ3id7"
   },
   "source": [
    "### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlduHU2CovxC"
   },
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# model.fit(x_train, np.array(y_train), epochs = 1, batch_size=batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39977, 400)\n",
      "(9995, 400)\n",
      "(39977, 20)\n",
      "(9995, 20)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], 400,))\n",
    "x_val = np.reshape(x_val, (x_val.shape[0], 400,))\n",
    "x_heading_train = np.reshape(x_heading_train, (x_heading_train.shape[0], 20,))\n",
    "x_heading_val = np.reshape(x_heading_val, (x_heading_val.shape[0], 20,))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_heading_train.shape)\n",
    "print(x_heading_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitAndCheck(epochs=1):\n",
    "    # happy learning!\n",
    "    model.fit({'articleInput':x_train, 'headingInput':x_heading_train}, {'stanceOutput':np.array(y_train)}, \n",
    "              #validation_data=({'articleInput':x_val, 'headingInput':x_heading_val}, {'stanceOutput':y_val}),\n",
    "              validation_split=0.1,\n",
    "              epochs=epochs, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CM3yCmjQoCM3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 28s - loss: 0.2868 - acc: 0.8857 - val_loss: 0.3938 - val_acc: 0.8534\n",
      "Epoch 2/5\n",
      "35979/35979 - 26s - loss: 0.2349 - acc: 0.9070 - val_loss: 0.2985 - val_acc: 0.8859\n",
      "Epoch 3/5\n",
      "35979/35979 - 26s - loss: 0.1983 - acc: 0.9203 - val_loss: 0.3771 - val_acc: 0.8542\n",
      "Epoch 4/5\n",
      "35979/35979 - 27s - loss: 0.1697 - acc: 0.9328 - val_loss: 0.2338 - val_acc: 0.9185\n",
      "Epoch 5/5\n",
      "35979/35979 - 27s - loss: 0.1470 - acc: 0.9421 - val_loss: 0.2607 - val_acc: 0.9157\n",
      "\n",
      "LSTM model accuracy score  :  0.9132566283141571\n",
      "LSTM model confusion matrix: \n",
      " [[ 407   21   18   31]\n",
      " [  78   87    6   16]\n",
      " [  29    4 1401   73]\n",
      " [ 205   32  354 7233]]\n",
      "Higher accuracy found, saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|████                                                                              | 1/20 [02:29<47:15, 149.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 28s - loss: 0.1340 - acc: 0.9484 - val_loss: 0.2252 - val_acc: 0.9260\n",
      "Epoch 2/5\n",
      "35979/35979 - 27s - loss: 0.1239 - acc: 0.9530 - val_loss: 0.2203 - val_acc: 0.9310\n",
      "Epoch 3/5\n",
      "35979/35979 - 27s - loss: 0.1084 - acc: 0.9594 - val_loss: 0.2111 - val_acc: 0.9317\n",
      "Epoch 4/5\n",
      "35979/35979 - 27s - loss: 0.0955 - acc: 0.9638 - val_loss: 0.4528 - val_acc: 0.8819\n",
      "Epoch 5/5\n",
      "35979/35979 - 27s - loss: 0.0860 - acc: 0.9674 - val_loss: 0.3146 - val_acc: 0.9167\n",
      "\n",
      "LSTM model accuracy score  :  0.9163581790895448\n",
      "LSTM model confusion matrix: \n",
      " [[ 574   46   33  255]\n",
      " [  29   84    0   10]\n",
      " [  42    4 1647  234]\n",
      " [  74   10   99 6854]]\n",
      "Higher accuracy found, saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|████████▏                                                                         | 2/20 [04:59<44:51, 149.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 27s - loss: 0.0787 - acc: 0.9719 - val_loss: 0.4675 - val_acc: 0.9075\n",
      "Epoch 2/5\n",
      "35979/35979 - 27s - loss: 0.0778 - acc: 0.9731 - val_loss: 0.2566 - val_acc: 0.9322\n",
      "Epoch 3/5\n",
      "35979/35979 - 27s - loss: 0.0705 - acc: 0.9754 - val_loss: 0.2217 - val_acc: 0.9462\n",
      "Epoch 4/5\n",
      "35979/35979 - 28s - loss: 0.0625 - acc: 0.9781 - val_loss: 0.2315 - val_acc: 0.9395\n",
      "Epoch 5/5\n",
      "35979/35979 - 28s - loss: 0.0605 - acc: 0.9786 - val_loss: 0.3959 - val_acc: 0.9155\n",
      "\n",
      "LSTM model accuracy score  :  0.9149574787393697\n",
      "LSTM model confusion matrix: \n",
      " [[ 518   13   34   65]\n",
      " [  52  110   24   31]\n",
      " [  25    3 1338   78]\n",
      " [ 124   18  383 7179]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|████████████▎                                                                     | 3/20 [07:32<42:38, 150.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 28s - loss: 0.0557 - acc: 0.9815 - val_loss: 0.3647 - val_acc: 0.9327\n",
      "Epoch 2/5\n",
      "35979/35979 - 28s - loss: 0.0534 - acc: 0.9816 - val_loss: 0.3430 - val_acc: 0.9240\n",
      "Epoch 3/5\n",
      "35979/35979 - 28s - loss: 0.0505 - acc: 0.9833 - val_loss: 0.2358 - val_acc: 0.9490\n",
      "Epoch 4/5\n",
      "35979/35979 - 28s - loss: 0.0491 - acc: 0.9840 - val_loss: 0.3039 - val_acc: 0.9422\n",
      "Epoch 5/5\n",
      "35979/35979 - 28s - loss: 0.0467 - acc: 0.9858 - val_loss: 0.2215 - val_acc: 0.9560\n",
      "\n",
      "LSTM model accuracy score  :  0.951975987993997\n",
      "LSTM model confusion matrix: \n",
      " [[ 599   12   29   70]\n",
      " [  24  121    4   17]\n",
      " [  35    5 1659  130]\n",
      " [  61    6   87 7136]]\n",
      "Higher accuracy found, saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|████████████████▍                                                                 | 4/20 [10:08<40:36, 152.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 28s - loss: 0.0420 - acc: 0.9860 - val_loss: 0.3432 - val_acc: 0.9432\n",
      "Epoch 2/5\n",
      "35979/35979 - 28s - loss: 0.0436 - acc: 0.9861 - val_loss: 0.2521 - val_acc: 0.9567\n",
      "Epoch 3/5\n",
      "35979/35979 - 28s - loss: 0.0408 - acc: 0.9869 - val_loss: 0.2878 - val_acc: 0.9517\n",
      "Epoch 4/5\n",
      "35979/35979 - 27s - loss: 0.0397 - acc: 0.9877 - val_loss: 0.4255 - val_acc: 0.9407\n",
      "Epoch 5/5\n",
      "35979/35979 - 27s - loss: 0.0416 - acc: 0.9875 - val_loss: 0.3820 - val_acc: 0.9322\n",
      "\n",
      "LSTM model accuracy score  :  0.9326663331665833\n",
      "LSTM model confusion matrix: \n",
      " [[ 616   23   28  129]\n",
      " [  11  112    0   10]\n",
      " [  38    4 1601  221]\n",
      " [  54    5  150 6993]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|████████████████████▌                                                             | 5/20 [12:40<38:03, 152.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 28s - loss: 0.0431 - acc: 0.9880 - val_loss: 0.3606 - val_acc: 0.9527\n",
      "Epoch 2/5\n",
      "35979/35979 - 27s - loss: 0.0390 - acc: 0.9889 - val_loss: 0.4106 - val_acc: 0.9537\n",
      "Epoch 3/5\n",
      "35979/35979 - 28s - loss: 0.0372 - acc: 0.9892 - val_loss: 0.4419 - val_acc: 0.9295\n",
      "Epoch 4/5\n",
      "35979/35979 - 27s - loss: 0.0413 - acc: 0.9887 - val_loss: 0.3162 - val_acc: 0.9577\n",
      "Epoch 5/5\n",
      "35979/35979 - 27s - loss: 0.0380 - acc: 0.9901 - val_loss: 0.3125 - val_acc: 0.9525\n",
      "\n",
      "LSTM model accuracy score  :  0.9559779889944973\n",
      "LSTM model confusion matrix: \n",
      " [[ 619   18   29   83]\n",
      " [  14  118    6   13]\n",
      " [  29    4 1654   93]\n",
      " [  57    4   90 7164]]\n",
      "Higher accuracy found, saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|████████████████████████▌                                                         | 6/20 [15:13<35:32, 152.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 28s - loss: 0.0338 - acc: 0.9895 - val_loss: 0.4065 - val_acc: 0.9412\n",
      "Epoch 2/5\n",
      "35979/35979 - 28s - loss: 0.0365 - acc: 0.9903 - val_loss: 0.3274 - val_acc: 0.9520\n",
      "Epoch 3/5\n",
      "35979/35979 - 27s - loss: 0.0383 - acc: 0.9892 - val_loss: 0.3636 - val_acc: 0.9555\n",
      "Epoch 4/5\n",
      "35979/35979 - 26s - loss: 0.0332 - acc: 0.9907 - val_loss: 0.3301 - val_acc: 0.9540\n",
      "Epoch 5/5\n",
      "35979/35979 - 28s - loss: 0.0351 - acc: 0.9901 - val_loss: 0.4697 - val_acc: 0.9525\n",
      "\n",
      "LSTM model accuracy score  :  0.9530765382691345\n",
      "LSTM model confusion matrix: \n",
      " [[ 562   11   14   45]\n",
      " [  16  122    2   12]\n",
      " [  49    4 1626   80]\n",
      " [  92    7  137 7216]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|████████████████████████████▋                                                     | 7/20 [17:45<32:59, 152.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 28s - loss: 0.0323 - acc: 0.9908 - val_loss: 0.3686 - val_acc: 0.9495\n",
      "Epoch 2/5\n",
      "35979/35979 - 28s - loss: 0.0330 - acc: 0.9914 - val_loss: 0.3702 - val_acc: 0.9577\n",
      "Epoch 3/5\n",
      "35979/35979 - 28s - loss: 0.0350 - acc: 0.9903 - val_loss: 0.3437 - val_acc: 0.9482\n",
      "Epoch 4/5\n",
      "35979/35979 - 27s - loss: 0.0381 - acc: 0.9912 - val_loss: 0.3402 - val_acc: 0.9567\n",
      "Epoch 5/5\n",
      "35979/35979 - 27s - loss: 0.0458 - acc: 0.9907 - val_loss: 0.3859 - val_acc: 0.9505\n",
      "\n",
      "LSTM model accuracy score  :  0.9501750875437719\n",
      "LSTM model confusion matrix: \n",
      " [[ 590   12   37   67]\n",
      " [  13  118    4   13]\n",
      " [  25    4 1604   88]\n",
      " [  91   10  134 7185]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████████████████████████████████▊                                                 | 8/20 [20:18<30:31, 152.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 28s - loss: 0.0338 - acc: 0.9915 - val_loss: 0.3773 - val_acc: 0.9522\n",
      "Epoch 2/5\n",
      "35979/35979 - 28s - loss: 0.0352 - acc: 0.9915 - val_loss: 0.3764 - val_acc: 0.9590\n",
      "Epoch 3/5\n",
      "35979/35979 - 28s - loss: 0.0350 - acc: 0.9908 - val_loss: 0.4311 - val_acc: 0.9527\n",
      "Epoch 4/5\n",
      "35979/35979 - 29s - loss: 0.0462 - acc: 0.9900 - val_loss: 0.4926 - val_acc: 0.9512\n",
      "Epoch 5/5\n",
      "35979/35979 - 27s - loss: 0.0362 - acc: 0.9918 - val_loss: 0.4444 - val_acc: 0.9465\n",
      "\n",
      "LSTM model accuracy score  :  0.9463731865932966\n",
      "LSTM model confusion matrix: \n",
      " [[ 581   17   29   91]\n",
      " [  21  114    1   26]\n",
      " [  38    4 1654  126]\n",
      " [  79    9   95 7110]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████████████████████████████████████▉                                             | 9/20 [22:52<28:03, 153.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 27s - loss: 0.0350 - acc: 0.9907 - val_loss: 0.3163 - val_acc: 0.9602\n",
      "Epoch 2/5\n",
      "35979/35979 - 27s - loss: 0.0375 - acc: 0.9913 - val_loss: 0.4804 - val_acc: 0.9422\n",
      "Epoch 3/5\n",
      "35979/35979 - 27s - loss: 0.0312 - acc: 0.9920 - val_loss: 0.3332 - val_acc: 0.9577\n",
      "Epoch 4/5\n",
      "35979/35979 - 26s - loss: 0.0378 - acc: 0.9907 - val_loss: 0.3718 - val_acc: 0.9565\n",
      "Epoch 5/5\n",
      "35979/35979 - 27s - loss: 0.0326 - acc: 0.9915 - val_loss: 0.4750 - val_acc: 0.9547\n",
      "\n",
      "LSTM model accuracy score  :  0.9531765882941471\n",
      "LSTM model confusion matrix: \n",
      " [[ 621   13   30   93]\n",
      " [  13  126    1   22]\n",
      " [  43    3 1669  127]\n",
      " [  42    2   79 7111]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|████████████████████████████████████████▌                                        | 10/20 [25:21<25:16, 151.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 28s - loss: 0.0399 - acc: 0.9910 - val_loss: 0.3906 - val_acc: 0.9467\n",
      "Epoch 2/5\n",
      "35979/35979 - 26s - loss: 0.0355 - acc: 0.9915 - val_loss: 0.3047 - val_acc: 0.9547\n",
      "Epoch 3/5\n",
      "35979/35979 - 27s - loss: 0.0378 - acc: 0.9916 - val_loss: 0.4678 - val_acc: 0.9490\n",
      "Epoch 4/5\n",
      "35979/35979 - 28s - loss: 0.0308 - acc: 0.9926 - val_loss: 0.4097 - val_acc: 0.9462\n",
      "Epoch 5/5\n",
      "35979/35979 - 26s - loss: 0.0303 - acc: 0.9917 - val_loss: 0.4019 - val_acc: 0.9277\n",
      "\n",
      "LSTM model accuracy score  :  0.9260630315157579\n",
      "LSTM model confusion matrix: \n",
      " [[ 568    8   17   73]\n",
      " [  25  122    8   39]\n",
      " [  18    5 1423   98]\n",
      " [ 108    9  331 7143]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|████████████████████████████████████████████▌                                    | 11/20 [27:49<22:36, 150.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 27s - loss: 0.0383 - acc: 0.9919 - val_loss: 0.3434 - val_acc: 0.9500\n",
      "Epoch 2/5\n",
      "35979/35979 - 28s - loss: 0.0380 - acc: 0.9919 - val_loss: 0.3951 - val_acc: 0.9562\n",
      "Epoch 3/5\n",
      "35979/35979 - 27s - loss: 0.0403 - acc: 0.9913 - val_loss: 0.4340 - val_acc: 0.9612\n",
      "Epoch 4/5\n",
      "35979/35979 - 27s - loss: 0.0350 - acc: 0.9924 - val_loss: 0.6390 - val_acc: 0.9502\n",
      "Epoch 5/5\n",
      "35979/35979 - 27s - loss: 0.0312 - acc: 0.9926 - val_loss: 0.6102 - val_acc: 0.9405\n",
      "\n",
      "LSTM model accuracy score  :  0.9340670335167583\n",
      "LSTM model confusion matrix: \n",
      " [[ 603   12   44   99]\n",
      " [  16  118    3   31]\n",
      " [  21    3 1488   96]\n",
      " [  79   11  244 7127]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|████████████████████████████████████████████████▌                                | 12/20 [30:19<20:02, 150.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 28s - loss: 0.0375 - acc: 0.9917 - val_loss: 0.5766 - val_acc: 0.9575\n",
      "Epoch 2/5\n",
      "35979/35979 - 27s - loss: 0.0356 - acc: 0.9924 - val_loss: 0.3728 - val_acc: 0.9570\n",
      "Epoch 3/5\n",
      "35979/35979 - 27s - loss: 0.0316 - acc: 0.9924 - val_loss: 0.4808 - val_acc: 0.9587\n",
      "Epoch 4/5\n",
      "35979/35979 - 26s - loss: 0.0408 - acc: 0.9917 - val_loss: 0.6436 - val_acc: 0.9425\n",
      "Epoch 5/5\n",
      "35979/35979 - 25s - loss: 0.0322 - acc: 0.9929 - val_loss: 0.4743 - val_acc: 0.9537\n",
      "\n",
      "LSTM model accuracy score  :  0.9542771385692846\n",
      "LSTM model confusion matrix: \n",
      " [[ 625    9   52   73]\n",
      " [  16  130    8   19]\n",
      " [  28    2 1652  130]\n",
      " [  50    3   67 7131]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|████████████████████████████████████████████████████▋                            | 13/20 [32:47<17:27, 149.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 27s - loss: 0.0378 - acc: 0.9919 - val_loss: 0.8045 - val_acc: 0.9577\n",
      "Epoch 2/5\n",
      "35979/35979 - 28s - loss: 0.0389 - acc: 0.9916 - val_loss: 0.4445 - val_acc: 0.9387\n",
      "Epoch 3/5\n",
      "35979/35979 - 27s - loss: 0.0345 - acc: 0.9922 - val_loss: 0.4641 - val_acc: 0.9592\n",
      "Epoch 4/5\n",
      "35979/35979 - 28s - loss: 0.0373 - acc: 0.9920 - val_loss: 0.3532 - val_acc: 0.9580\n",
      "Epoch 5/5\n",
      "35979/35979 - 27s - loss: 0.0386 - acc: 0.9917 - val_loss: 0.3983 - val_acc: 0.9570\n",
      "\n",
      "LSTM model accuracy score  :  0.9565782891445723\n",
      "LSTM model confusion matrix: \n",
      " [[ 622   14   25   88]\n",
      " [  11  124    1    9]\n",
      " [  32    3 1678  119]\n",
      " [  54    3   75 7137]]\n",
      "Higher accuracy found, saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|████████████████████████████████████████████████████████▋                        | 14/20 [35:21<15:05, 150.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 27s - loss: 0.0358 - acc: 0.9922 - val_loss: 0.5263 - val_acc: 0.9595\n",
      "Epoch 2/5\n",
      "35979/35979 - 27s - loss: 0.0367 - acc: 0.9922 - val_loss: 0.4557 - val_acc: 0.9567\n",
      "Epoch 3/5\n",
      "35979/35979 - 27s - loss: 0.0468 - acc: 0.9907 - val_loss: 0.4012 - val_acc: 0.9485\n",
      "Epoch 4/5\n",
      "35979/35979 - 27s - loss: 0.0371 - acc: 0.9913 - val_loss: 0.6385 - val_acc: 0.9550\n",
      "Epoch 5/5\n",
      "35979/35979 - 28s - loss: 0.0439 - acc: 0.9917 - val_loss: 0.4905 - val_acc: 0.9447\n",
      "\n",
      "LSTM model accuracy score  :  0.9502751375687843\n",
      "LSTM model confusion matrix: \n",
      " [[ 602   26   19   87]\n",
      " [  22  107    2   13]\n",
      " [  29    3 1676  140]\n",
      " [  66    8   82 7113]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|████████████████████████████████████████████████████████████▊                    | 15/20 [37:51<12:33, 150.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 27s - loss: 0.0512 - acc: 0.9927 - val_loss: 1.2458 - val_acc: 0.8904\n",
      "Epoch 2/5\n",
      "35979/35979 - 26s - loss: 0.0402 - acc: 0.9930 - val_loss: 0.4290 - val_acc: 0.9572\n",
      "Epoch 3/5\n",
      "35979/35979 - 26s - loss: 0.0402 - acc: 0.9924 - val_loss: 0.3538 - val_acc: 0.9530\n",
      "Epoch 4/5\n",
      "35979/35979 - 27s - loss: 0.0466 - acc: 0.9916 - val_loss: 0.4197 - val_acc: 0.9620\n",
      "Epoch 5/5\n",
      "35979/35979 - 26s - loss: 0.0341 - acc: 0.9917 - val_loss: 1.9050 - val_acc: 0.9297\n",
      "\n",
      "LSTM model accuracy score  :  0.9352676338169085\n",
      "LSTM model confusion matrix: \n",
      " [[ 570    7   22   56]\n",
      " [  28  126    4   11]\n",
      " [  22    3 1410   44]\n",
      " [  99    8  343 7242]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████████████████████████████████████████████████████████████▊                | 16/20 [40:18<09:58, 149.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 27s - loss: 0.0448 - acc: 0.9919 - val_loss: 0.4271 - val_acc: 0.9597\n",
      "Epoch 2/5\n",
      "35979/35979 - 25s - loss: 0.0344 - acc: 0.9924 - val_loss: 0.3652 - val_acc: 0.9557\n",
      "Epoch 3/5\n",
      "35979/35979 - 27s - loss: 0.0366 - acc: 0.9928 - val_loss: 0.3641 - val_acc: 0.9605\n",
      "Epoch 4/5\n",
      "35979/35979 - 26s - loss: 0.0372 - acc: 0.9924 - val_loss: 0.3954 - val_acc: 0.9605\n",
      "Epoch 5/5\n",
      "35979/35979 - 27s - loss: 0.0387 - acc: 0.9926 - val_loss: 0.5005 - val_acc: 0.9555\n",
      "\n",
      "LSTM model accuracy score  :  0.9585792896448224\n",
      "LSTM model confusion matrix: \n",
      " [[ 591   10   14   51]\n",
      " [  12  125    1   12]\n",
      " [  40    3 1688  113]\n",
      " [  76    6   76 7177]]\n",
      "Higher accuracy found, saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████████████████████████████████████████████████████████████████▊            | 17/20 [42:45<07:26, 148.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 26s - loss: 0.0291 - acc: 0.9929 - val_loss: 0.3280 - val_acc: 0.9602\n",
      "Epoch 2/5\n",
      "35979/35979 - 27s - loss: 0.0397 - acc: 0.9924 - val_loss: 0.7155 - val_acc: 0.9597\n",
      "Epoch 3/5\n",
      "35979/35979 - 26s - loss: 0.0428 - acc: 0.9944 - val_loss: 0.6640 - val_acc: 0.9537\n",
      "Epoch 4/5\n",
      "35979/35979 - 28s - loss: 0.3511 - acc: 0.9928 - val_loss: 0.6671 - val_acc: 0.9600\n",
      "Epoch 5/5\n",
      "35979/35979 - 28s - loss: 0.0367 - acc: 0.9928 - val_loss: 0.5340 - val_acc: 0.9555\n",
      "\n",
      "LSTM model accuracy score  :  0.960280140070035\n",
      "LSTM model confusion matrix: \n",
      " [[ 593    7   22   46]\n",
      " [  41  134    7   26]\n",
      " [  34    3 1676   86]\n",
      " [  51    0   74 7195]]\n",
      "Higher accuracy found, saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|████████████████████████████████████████████████████████████████████████▉        | 18/20 [45:15<04:58, 149.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 28s - loss: 0.0503 - acc: 0.9926 - val_loss: 0.4838 - val_acc: 0.9585\n",
      "Epoch 2/5\n",
      "35979/35979 - 27s - loss: 0.0336 - acc: 0.9932 - val_loss: 0.6353 - val_acc: 0.9577\n",
      "Epoch 3/5\n",
      "35979/35979 - 27s - loss: 0.0362 - acc: 0.9931 - val_loss: 0.8665 - val_acc: 0.9477\n",
      "Epoch 4/5\n",
      "35979/35979 - 27s - loss: 0.0460 - acc: 0.9925 - val_loss: 0.7409 - val_acc: 0.9452\n",
      "Epoch 5/5\n",
      "35979/35979 - 27s - loss: 0.0322 - acc: 0.9926 - val_loss: 0.7537 - val_acc: 0.9530\n",
      "\n",
      "LSTM model accuracy score  :  0.9573786893446723\n",
      "LSTM model confusion matrix: \n",
      " [[ 623    9   22   71]\n",
      " [  20  132    3   20]\n",
      " [  39    2 1691  139]\n",
      " [  37    1   63 7123]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|████████████████████████████████████████████████████████████████████████████▉    | 19/20 [47:47<02:30, 150.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35979 samples, validate on 3998 samples\n",
      "Epoch 1/5\n",
      "35979/35979 - 28s - loss: 0.0343 - acc: 0.9917 - val_loss: 0.4850 - val_acc: 0.9575\n",
      "Epoch 2/5\n",
      "35979/35979 - 26s - loss: 0.0301 - acc: 0.9934 - val_loss: 0.8594 - val_acc: 0.9622\n",
      "Epoch 3/5\n",
      "35979/35979 - 25s - loss: 0.0447 - acc: 0.9924 - val_loss: 0.9792 - val_acc: 0.9432\n",
      "Epoch 4/5\n",
      "35979/35979 - 27s - loss: 0.0375 - acc: 0.9936 - val_loss: 0.7541 - val_acc: 0.9637\n",
      "Epoch 5/5\n",
      "35979/35979 - 26s - loss: 0.0586 - acc: 0.9931 - val_loss: 0.4869 - val_acc: 0.9485\n",
      "\n",
      "LSTM model accuracy score  :  0.9526763381690846\n",
      "LSTM model confusion matrix: \n",
      " [[ 581   14   22   60]\n",
      " [  10  101    2    3]\n",
      " [  33   11 1626   76]\n",
      " [  95   18  129 7214]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 20/20 [50:14<00:00, 150.74s/it]\n"
     ]
    }
   ],
   "source": [
    "max_acc = 0\n",
    "\n",
    "for i in tqdm(range(20)):\n",
    "    fitAndCheck(5)\n",
    "    y_pred = model.predict({'articleInput':x_val, 'headingInput':x_heading_val})\n",
    "    #\n",
    "    acc = accuracy_score(np.argmax(y_pred, axis=1), np.argmax(np.array(y_val), axis=1))\n",
    "    con_mat = confusion_matrix(np.argmax(y_pred, axis=1), np.argmax(np.array(y_val), axis=1))\n",
    "    print()\n",
    "    print(\"LSTM model accuracy score  : \", acc)\n",
    "    #print()\n",
    "    print(\"LSTM model confusion matrix: \\n\", con_mat)\n",
    "    \n",
    "    if acc > max_acc:\n",
    "        max_acc = acc\n",
    "        print('Higher accuracy found, saving model...')\n",
    "        modelBaseName = 'modelData/cnn_stance_' +str((i+1)*5) + '_' + str(int(round(acc*100, 0)))\n",
    "        model.save(modelBaseName + '.h5')\n",
    "        model.save_weights(modelBaseName + '_weights.h5')\n",
    "    #print()\n",
    "    #print(\"LSTM model classification report: \\n\", classification_report(np.argmax(y_pred, axis=1), \n",
    "    #                                                                    np.argmax(np.array(y_val), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.argmax(y_pred, axis=1)[0:10])\n",
    "# print(np.argmax(np.array(y_val), axis=1)[0:10])\n",
    "# acc = accuracy_score(np.argmax(y_pred, axis=1), np.argmax(np.array(y_val), axis=1))\n",
    "# con_mat = confusion_matrix(np.argmax(y_pred, axis=1), np.argmax(np.array(y_val), axis=1))\n",
    "# print(\"LSTM model accuracy score  : \", acc)\n",
    "# print()\n",
    "# print(\"LSTM model confusion matrix: \\n\", con_mat)\n",
    "# print()\n",
    "# print(\"LSTM model classification report: \\n\", classification_report(np.argmax(y_pred, axis=1), \n",
    "#                                                                     np.argmax(np.array(y_val), axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R47A6Ysfev3l"
   },
   "source": [
    "## Build the same model with attention layers included for better performance (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQ3TWuiAe1Uu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wivJ-eVkfEOm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "olqo5ytRe7eq"
   },
   "source": [
    "## Fit the model and report the accuracy score for the model with attention layer (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zgxPrhzfBkv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8507P94fDuX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRAS\n",
    "\n",
    "REFERENCE:\n",
    "- https://machinelearningmastery.com/encoder-decoder-attention-sequence-to-sequence-prediction-keras/\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 47, 25, 33, 46]\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "# generate a sequence of random integers\n",
    "def generate_sequence(length, n_unique):\n",
    "    return [randint(0, n_unique-1) for _ in range(length)]\n",
    "\n",
    "# generate random sequence\n",
    "sequence = generate_sequence(5, 50)\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode sequence\n",
    "def one_hot_encode(sequence, n_unique):\n",
    "    encoding = list()\n",
    "    for value in sequence:\n",
    "        vector = [0 for _ in range(n_unique)]\n",
    "        vector[value] = 1\n",
    "        encoding.append(vector)\n",
    "    return array(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Stance_Detection_for_the_Fake_News_Challenge_Questions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
