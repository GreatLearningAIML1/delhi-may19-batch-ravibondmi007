{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective:\n",
    "Can you differentiate a weed from a crop seedling? Given an image\n",
    "differentiate between different plant types.\n",
    "\n",
    "Tthis dataset gives you an opportunity to experiment with different image\n",
    "recognition techniques, as well to provide a place to cross-pollenate ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context:\n",
    "The ability to do so effectively can mean better crop yields and better stewardship of the environment.\n",
    "\n",
    "The Aarhus University Signal Processing group, in collaboration with University of Southern Denmark, has recently released a dataset containing images of approximately 960 unique plants belonging to 12 species at several growth stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description:\n",
    "You are provided with a training set and a test set of images of plant seedlings at various stages of grown. Each image has a filename that is its unique id. The dataset comprises 12 plant species. The goal of the competition is to create a classifier capable of determining a plant's species from a photo. The list of species is as follows:\n",
    "- Black-grass\n",
    "- Charlock\n",
    "- Cleavers\n",
    "- Common Chickweed\n",
    "- Common wheat\n",
    "- Fat Hen\n",
    "- Loose Silky-bent\n",
    "- Maize\n",
    "- Scentless Mayweed\n",
    "- Shepherds Purse\n",
    "- Small-flowered Cranesbill\n",
    "- Sugar beet\n",
    "\n",
    "Know more at :\n",
    "https://www.kaggle.com/c/plant-seedlings-classification/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps and Milestones (100%):\n",
    "- Setup Environment and Load Necessary Packages (5%)\n",
    "- Data Preparation (40%)\n",
    "    - Loading Data (5%)\n",
    "    - Cleaning Data (10%)\n",
    "    - Data Representation & Feature Engineering (If Any) (15%)\n",
    "    - Creating Train and Validation Set (10%)\n",
    "\n",
    "- Model Creation (30%)\n",
    "    - Write & Configure Model (10%)\n",
    "    - Compile Model (10%)\n",
    "    - Build Model & Checking Summary (10%)\n",
    "\n",
    "- Training and Evaluation (25%)\n",
    "    - Run Multiple Experiments (10%)\n",
    "    - Reason & Visualize Model Performance (5%)\n",
    "    - Evaluate Model on Test Set (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Outcomes:\n",
    "- Image classification\n",
    "- Neural Networks\n",
    "- Convolutional Neural Networks\n",
    "- Dynamic Input Image Pipeline\n",
    "- Fine-tuning Model\n",
    "- Data Preparation\n",
    "- Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEPS\n",
    "1. Read the images and generate the train and test dataset (5 points)\n",
    "2. Divide the data set into Train and validation data sets\n",
    "3. Initialize & build the model (10 points)\n",
    "4. Optimize the model (8 points)\n",
    "5. Predict the accuracy for both train and validation data (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1\n",
    "Read the images and generate the train and test dataset (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through folders\n",
    "    # In each folder, read each image\n",
    "        # Resize the images to common size (say 128 * 128)\n",
    "        # Save the images pixel values, after resizing, along with the classification value in a list of array of arrays\n",
    "        # Save the data to a file (probably to .h5)\n",
    "# Work on the saved file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "\n",
    "# For viewing the image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Importing opencv module for the resizing function\n",
    "import cv2\n",
    "\n",
    "import glob, os\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir_trainingData = 'D:/workingDirectory/PROJECTS/11 - PROJECT - R7 - 01 - Computer Vision with CNN/plant-seedlings-classification/train'\n",
    "\n",
    "rootdir_testingData = 'D:/workingDirectory/PROJECTS/11 - PROJECT - R7 - 01 - Computer Vision with CNN/plant-seedlings-classification/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for subdir, dirs, files in os.walk(rootdir):\n",
    "#     for directory in dirs:\n",
    "#         print(directory)\n",
    "\n",
    "# for subdir, dirs, files in os.walk(rootdir):\n",
    "#     for file in files:\n",
    "#         print(os.path.join(subdir, file))\n",
    "\n",
    "# for subdir, dirs, files in os.walk(rootdir):\n",
    "#     for directory in dirs:\n",
    "#         print(directory)\n",
    "#         for file in files:\n",
    "#             img = io.imread('IMG_20190821_113948.jpg')\n",
    "\n",
    "# img = io.imread(os.path.join(rootdir + \"/\" + \"Black-grass\", \"0ace21089.png\"))\n",
    "# plt.figure(figsize=[10,10])\n",
    "# plt.imshow(img)\n",
    "\n",
    "# plt.figure(figsize=[10,10])\n",
    "# plt.imshow(img_res.astype('uint8'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeToDesiredShape(inputImage, h, w):\n",
    "    # Seperate the r, g, b layers\n",
    "    r_array = np.array(inputImage[:, :, 0])\n",
    "    g_array = np.array(inputImage[:, :, 1])\n",
    "    b_array = np.array(inputImage[:, :, 2])\n",
    "    \n",
    "    # Apply resize on each layer (r, g, b)\n",
    "    r_res = cv2.resize(r_array, dsize=(h, w), interpolation=cv2.INTER_CUBIC)\n",
    "    g_res = cv2.resize(r_array, dsize=(h, w), interpolation=cv2.INTER_CUBIC)\n",
    "    b_res = cv2.resize(r_array, dsize=(h, w), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Prepare image using the resized r, g, b\n",
    "    outputImage = np.array([r_res, g_res, b_res])  # Put the reshaped values into a array\n",
    "    outputImage = np.transpose(outputImage, (1, 2, 0))  # Swap the dimensions of the array\n",
    "\n",
    "    return outputImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the images, reshize them and add to an list\n",
    "def generateX_y(rootDir, h=512, w=512, y_inOut = True):\n",
    "    X_out = []\n",
    "    y_out = []\n",
    "    \n",
    "    # Get all possible seed types (=folder names)\n",
    "    if y_inOut:\n",
    "        possibleY = []\n",
    "        for subdir, dirs, files in os.walk(rootdir_trainingData):\n",
    "            possibleY = dirs\n",
    "            break\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(rootDir):\n",
    "        for file in files:\n",
    "            \n",
    "            # Append y\n",
    "            if y_inOut:\n",
    "                presentDirLabel = subdir.split(\"\\\\\")[-1]\n",
    "                presentDirIndex = possibleY.index(presentDirLabel)\n",
    "                y_out.append(presentDirIndex)\n",
    "            # Resize and append X\n",
    "            img = io.imread(os.path.join(subdir, file))\n",
    "            img_res = resizeToDesiredShape(img, h, w)\n",
    "            \n",
    "            X_out.append(img_res)\n",
    "    return X_out, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dim_h = 128  # Resize height\n",
    "res_dim_w = 128  # Resize width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = generateX_y(rootdir_trainingData, res_dim_h, res_dim_w)\n",
    "X_test, y_test = generateX_y(rootdir_testingData, res_dim_h, res_dim_w, y_inOut=False)\n",
    "\n",
    "print(len(X_train))  # Should return 4750\n",
    "print(len(X_test))  # Should return 794"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to HDF5 file (commented to avoid running again)\n",
    "\n",
    "# hf = h5py.File('data_plant_seed_resizedImages.h5', 'w')  # Create file with write(w) access\n",
    "# hf.create_dataset('X_train_val', data=X_train)\n",
    "# hf.create_dataset('y_train_val', data=y_train)\n",
    "# hf.create_dataset('X_test', data=X_test)\n",
    "# hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['X_test', 'X_train_val', 'y_train_val']>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5 = h5py.File('data_plant_seed_resizedImages.h5', 'r')\n",
    "h5.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('data_plant_seed_resizedImages.h5', 'r')\n",
    "X_train_val = h5f['X_train_val'][:]\n",
    "y_train_val = h5f['y_train_val'][:]\n",
    "X_test = h5f['X_test'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2\n",
    "Divide the data set into Train and validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3325\n",
      "1425\n",
      "3325\n",
      "1425\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_val))\n",
    "print(len(y_train))\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3\n",
    "Initialize & build the model (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to array\n",
    "X_train = np.asarray(X_train)\n",
    "X_val = np.asarray(X_val)\n",
    "X_test = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save normalized value to .h5 file (commented to avoid running again)\n",
    "\n",
    "# hf = h5py.File('data_plant_seed_resizedImages_float_normalized.h5', 'w')  # Create file with write(w) access\n",
    "# hf.create_dataset('X_train', data=X_train)\n",
    "# hf.create_dataset('y_train', data=y_train)\n",
    "# hf.create_dataset('X_val', data=X_val)\n",
    "# hf.create_dataset('y_val', data=y_val)\n",
    "# hf.create_dataset('X_test', data=X_test)\n",
    "# hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['X_test', 'X_train', 'X_val', 'y_train', 'y_val']>\n"
     ]
    }
   ],
   "source": [
    "# Read normalized value from .h5 file\n",
    "h5 = h5py.File('data_plant_seed_resizedImages_float_normalized.h5', 'r')\n",
    "print(h5.keys())\n",
    "\n",
    "X_train = h5['X_train'][:]\n",
    "y_train = h5['y_train'][:]\n",
    "X_val = h5['X_val'][:]\n",
    "y_val = h5['y_val'][:]\n",
    "# X_test = h5['X_test'][:]  # Don't read while modelling for saving memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 12\n",
    "epochs = 10\n",
    "classLabel_inOrderOfIndex = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', \n",
    "                             'Common wheat', 'Fat Hen', 'Loose Silky-bent', 'Maize', \n",
    "                             'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n",
    "input_shape = (res_dim_h, res_dim_w, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, backend\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train_cat = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val_cat = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buile CNN\n",
    "\n",
    "#Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "#Add a Convolutional Layer with 32 filters of size 3X3 and activation function as 'ReLU' \n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape,name='conv_1'))\n",
    "\n",
    "#Add a Convolutional Layer with 64 filters of size 3X3 and activation function as 'ReLU' \n",
    "model.add(Conv2D(64, (3, 3), activation='relu',name='conv_2'))\n",
    "\n",
    "#Add a MaxPooling Layer of size 2X2 \n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name='max_1'))\n",
    "\n",
    "#Apply Dropout with 0.25 probability \n",
    "model.add(Dropout(0.25,name='drop_1'))\n",
    "\n",
    "#Flatten the layer\n",
    "model.add(Flatten())\n",
    "\n",
    "#Add Fully Connected Layer with 128 units and activation function as 'ReLU'\n",
    "model.add(Dense(128, activation='relu',name='dense_1'))\n",
    "#Apply Dropout with 0.5 probability \n",
    "model.add(Dropout(0.5,name='drop_2'))\n",
    "\n",
    "#Add Fully Connected Layer with 10 units and activation function as 'softmax'\n",
    "model.add(Dense(num_classes, activation='softmax',name='dense_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To use adam optimizer for learning weights with learning rate = 0.001\n",
    "optimizer = Adam(lr=0.001)\n",
    "#Set the loss function and optimizer for the model training\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3325 samples, validate on 1425 samples\n",
      "Epoch 1/10\n",
      "3325/3325 [==============================] - 10s 3ms/sample - loss: 0.7461 - accuracy: 0.7149 - val_loss: 2.8983 - val_accuracy: 0.2716\n",
      "Epoch 2/10\n",
      "3325/3325 [==============================] - 10s 3ms/sample - loss: 0.7055 - accuracy: 0.7263 - val_loss: 2.9432 - val_accuracy: 0.2547\n",
      "Epoch 3/10\n",
      "3325/3325 [==============================] - 10s 3ms/sample - loss: 0.7012 - accuracy: 0.7341 - val_loss: 3.0683 - val_accuracy: 0.2611\n",
      "Epoch 4/10\n",
      "3325/3325 [==============================] - 10s 3ms/sample - loss: 0.6661 - accuracy: 0.7389 - val_loss: 3.0152 - val_accuracy: 0.2589\n",
      "Epoch 5/10\n",
      "3325/3325 [==============================] - 10s 3ms/sample - loss: 0.6147 - accuracy: 0.7642 - val_loss: 3.2727 - val_accuracy: 0.2618\n",
      "Epoch 6/10\n",
      "3325/3325 [==============================] - 10s 3ms/sample - loss: 0.6284 - accuracy: 0.7549 - val_loss: 3.4723 - val_accuracy: 0.2316\n",
      "Epoch 7/10\n",
      "3325/3325 [==============================] - 10s 3ms/sample - loss: 0.5907 - accuracy: 0.7729 - val_loss: 3.5381 - val_accuracy: 0.2582\n",
      "Epoch 8/10\n",
      "3325/3325 [==============================] - 10s 3ms/sample - loss: 0.5914 - accuracy: 0.7630 - val_loss: 3.2990 - val_accuracy: 0.2589\n",
      "Epoch 9/10\n",
      "3325/3325 [==============================] - 10s 3ms/sample - loss: 0.5893 - accuracy: 0.7660 - val_loss: 3.4356 - val_accuracy: 0.2554\n",
      "Epoch 10/10\n",
      "3325/3325 [==============================] - 10s 3ms/sample - loss: 0.5623 - accuracy: 0.7829 - val_loss: 3.2478 - val_accuracy: 0.2639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x168b0614808>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_cat,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the path where you want to store the model and weights. \n",
    "\n",
    "# model.save('./data/cnn_svhn.h5')\n",
    "# model.save_weights('./data/cnn_svhn_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4\n",
    "Optimize the model (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build optimized CNN\n",
    "    # Add BatchNormalization\n",
    "    # Kernel_initialization = he_normal\n",
    "    # More number of filters\n",
    "\n",
    "#Initialize the model\n",
    "model2 = Sequential()\n",
    "\n",
    "#Add a Convolutional Layer with 32 filters of size 3X3 and activation function as 'ReLU' \n",
    "model2.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape,name='conv_1'))\n",
    "\n",
    "#Add a Convolutional Layer with 64 filters of size 3X3 and activation function as 'ReLU' \n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "#Add a MaxPooling Layer of size 2X2 \n",
    "model2.add(MaxPooling2D(pool_size=(2, 2),name='max_1'))\n",
    "\n",
    "#Add a Convolutional Layer with 64 filters of size 3X3 and activation function as 'ReLU' \n",
    "model2.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "#Add a MaxPooling Layer of size 2X2 \n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Add a Convolutional Layer with 64 filters of size 3X3 and activation function as 'ReLU' \n",
    "model2.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "\n",
    "#Apply Dropout with 0.25 probability \n",
    "model2.add(Dropout(0.25,name='drop_1'))\n",
    "\n",
    "#Flatten the layer\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(keras.layers.BatchNormalization())\n",
    "#Add Fully Connected Layer with 128 units and activation function as 'ReLU'\n",
    "model2.add(Dense(64, activation='relu', kernel_initializer=\"he_normal\"))\n",
    "#Apply Dropout with 0.5 probability \n",
    "model2.add(Dropout(0.25,name='drop_2'))\n",
    "\n",
    "# model2.add(keras.layers.BatchNormalization())\n",
    "# #Add Fully Connected Layer with 128 units and activation function as 'ReLU'\n",
    "# model2.add(Dense(32, activation='relu', kernel_initializer=\"he_normal\"))\n",
    "# #Apply Dropout with 0.5 probability \n",
    "# model2.add(Dropout(0.25))\n",
    "\n",
    "#Add Fully Connected Layer with 10 units and activation function as 'softmax'\n",
    "model2.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To use adam optimizer for learning weights with learning rate = 0.001\n",
    "optimizer = Adam(lr=0.005)\n",
    "#Set the loss function and optimizer for the model training\n",
    "model2.compile(loss=categorical_crossentropy,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3325 samples, validate on 1425 samples\n",
      "Epoch 1/10\n",
      "3325/3325 [==============================] - 10s 3ms/sample - loss: 0.3689 - accuracy: 0.8716 - val_loss: 4.4691 - val_accuracy: 0.2765\n",
      "Epoch 2/10\n",
      "3325/3325 [==============================] - 10s 3ms/sample - loss: 0.3794 - accuracy: 0.8743 - val_loss: 4.9982 - val_accuracy: 0.2877\n",
      "Epoch 3/10\n",
      "3325/3325 [==============================] - 9s 3ms/sample - loss: 0.3861 - accuracy: 0.8674 - val_loss: 4.8125 - val_accuracy: 0.2989\n",
      "Epoch 4/10\n",
      "3325/3325 [==============================] - 9s 3ms/sample - loss: 0.3232 - accuracy: 0.8950 - val_loss: 4.5556 - val_accuracy: 0.3067\n",
      "Epoch 5/10\n",
      "3325/3325 [==============================] - 9s 3ms/sample - loss: 0.3523 - accuracy: 0.8830 - val_loss: 4.4287 - val_accuracy: 0.2919\n",
      "Epoch 6/10\n",
      "3325/3325 [==============================] - 9s 3ms/sample - loss: 0.3967 - accuracy: 0.8656 - val_loss: 4.8462 - val_accuracy: 0.2835\n",
      "Epoch 7/10\n",
      "3325/3325 [==============================] - 9s 3ms/sample - loss: 0.3328 - accuracy: 0.8902 - val_loss: 4.5874 - val_accuracy: 0.3179\n",
      "Epoch 8/10\n",
      "3325/3325 [==============================] - 10s 3ms/sample - loss: 0.3300 - accuracy: 0.8863 - val_loss: 4.5259 - val_accuracy: 0.3256\n",
      "Epoch 9/10\n",
      "3325/3325 [==============================] - 9s 3ms/sample - loss: 0.3138 - accuracy: 0.8917 - val_loss: 4.4803 - val_accuracy: 0.3263\n",
      "Epoch 10/10\n",
      "3325/3325 [==============================] - 9s 3ms/sample - loss: 0.3450 - accuracy: 0.8839 - val_loss: 4.7847 - val_accuracy: 0.3046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x210adc05488>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train_cat,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5\n",
    "Predict the accuracy for both train and validation data (7 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_model2 = model2.predict(X_train)\n",
    "y_val_pred_model2 = model2.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data confusion matrix\n",
      " [[174   0   0   0   0   0   2   0   0   0   1   1]\n",
      " [  0 280   0   0   0   0   0   0   0   0   1   0]\n",
      " [  0   0 210   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 424   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0 166   0   1   0   0   0   0   0]\n",
      " [  0   0   0   0   0 334   0   0   0   0   0   0]\n",
      " [  0   0   0   2   0   0 455   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0 154   0   0   0   0]\n",
      " [  0   0   0   3   0   0   0   0 361   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0 156   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 340   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0 256]]\n",
      "\n",
      "\n",
      "Validation data confusion matrix\n",
      " [[17  2  0 14  5  6 30  0  2  1  3  5]\n",
      " [ 6 38  9  1  3  7  4  3  9  5 20  4]\n",
      " [ 1 15 25  8  3  5  2  0  4  6  7  1]\n",
      " [ 2  3  4 95  4  9 16  8 24  7  5 10]\n",
      " [ 3  2  2  8  9  4  7  2  5  1  1  9]\n",
      " [ 4  4  1 38  3 35 25  3  5  7 11  5]\n",
      " [14  4  1 43  2 13 73  0 10  5 14 18]\n",
      " [ 4  4  2 28  3  3  2 10  6  2  1  1]\n",
      " [ 4  3  0 53  1  4 17  9 42 10  3  6]\n",
      " [ 1  3  2 16  1  9 10  2 12 10  4  4]\n",
      " [ 7 14  5 14  5 17 19  2 11  2 56  4]\n",
      " [ 8  3  0 22  6 15 34  2  5  3  6 24]]\n"
     ]
    }
   ],
   "source": [
    "# Use np.argmax to find the index of the max value in the row\n",
    "confusion_matrix_train = confusion_matrix(np.argmax(y_train_cat, axis=1), np.argmax(y_train_pred_model2, axis=1))\n",
    "confusion_matrix_val = confusion_matrix(np.argmax(y_val_cat, axis=1), np.argmax(y_val_pred_model2, axis=1))\n",
    "\n",
    "print(\"Train data confusion matrix\\n\", confusion_matrix_train)\n",
    "print(\"\\n\\nValidation data confusion matrix\\n\", confusion_matrix_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training data on the model:  0.9954887218045113\n",
      "Accuracy of validation data on the model:  0.3045614035087719\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = accuracy_score(np.argmax(y_train_cat, axis=1), np.argmax(y_train_pred_model2, axis=1))\n",
    "accuracy_val = accuracy_score(np.argmax(y_val_cat, axis=1), np.argmax(y_val_pred_model2, axis=1))\n",
    "\n",
    "print(\"Accuracy of training data on the model: \", accuracy_train)\n",
    "print(\"Accuracy of validation data on the model: \", accuracy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "- The model has high bias\n",
    "- As machine was not able to handle this large data, therefore, low resolution images(after resizing) were used. This probably caused lose of information which may have caused some accuracy lose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
